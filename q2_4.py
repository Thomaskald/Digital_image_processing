from scipy.cluster.vq import vq
import numpy as np
import glob
from skimage.feature import SIFT
import cv2
from PIL.Image import Image
from matplotlib import pyplot as plt

queen_path = glob.glob("Queen-Resized/*.jpg", recursive=True)
bishop_path = glob.glob("bishop_resized/*.jpg", recursive=True)
knight_path = glob.glob("knight-resize/*.jpg", recursive=True)
pawn_path = glob.glob("pawn_resized/*.jpg", recursive=True)
rook_path = glob.glob("Rook-resize/*.jpg", recursive=True)

image_paths = bishop_path + knight_path + pawn_path + queen_path + rook_path

images = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in image_paths]

sift = SIFT()
descriptors = []

images_valid = []
descriptors = []

for img in images:
    try:
        sift.detect_and_extract(img)
        if sift.descriptors is not None and len(sift.descriptors) > 0:
            descriptors.append(sift.descriptors)
            images_valid.append(img)  # Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Ï‡ÏÎ®ÏƒÎ¹Î¼ÎµÏ‚
    except RuntimeError:
        print("SIFT failed on one image. Skipping.")

images_gray = [cv2.imread(p, cv2.IMREAD_GRAYSCALE) for p in image_paths]

image_paths_valid = []
for img, path in zip(images_gray, image_paths):
    for valid_img in images_valid:
        if np.array_equal(img, valid_img):
            image_paths_valid.append(path)
            break

all_descriptors = np.vstack([desc for desc in descriptors if desc is not None]).astype(float)

# -------------------- 4. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· KMeans (Î»ÎµÎ¾Î¹ÎºÏŒ) --------------------
k = 200  # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ visual words
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
attempts = 10
flags = cv2.KMEANS_RANDOM_CENTERS

all_descriptors = all_descriptors.astype(np.float32)

compactness, labels, centers = cv2.kmeans(all_descriptors, k, None, criteria, attempts, flags)
codebook = centers

# -------------------- 5. Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· descriptors ÏƒÎµ visual words --------------------
visual_words = []
for desc in descriptors:
    if desc is not None:
        words, _ = vq(desc, codebook)
    else:
        words = np.array([])
    visual_words.append(words)

# -------------------- 6. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± BoVW vector (Î¹ÏƒÏ„ÏŒÎ³ÏÎ±Î¼Î¼Î±) --------------------
bovw_vectors = []
for words in visual_words:
    hist = np.zeros(k)
    for w in words:
        hist[w] += 1
    bovw_vectors.append(hist)

bovw_vectors = np.stack(bovw_vectors)

# -------------------- 7. (Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬) TF-IDF Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ --------------------
N = len(bovw_vectors)
df = np.sum(bovw_vectors > 0, axis=0)
idf = np.log(N / (df + 1e-6))  # Î¼Î¹ÎºÏÎ® Ï„Î¹Î¼Î® Î³Î¹Î± Î±Ï€Î¿Ï†Ï…Î³Î® log(0)
tf_idf = bovw_vectors * idf

# -------------------- 8. Î ÏÎ¿Î²Î¿Î»Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ --------------------



from matplotlib import image as mpimg
from sklearn.metrics import pairwise_distances
# B

from scipy.spatial.distance import cdist
import os

query_filenames = [
    "Queen-Resized/00000000_resized.jpg",
    "Queen-Resized/00000001_resized.jpg",
    "Rook-resize/00000001_resized.jpg",
    "Rook-resize/00000002_resized.jpg",
    "bishop_resized/00000000_resized.jpg",
    "bishop_resized/00000002_resized.jpg",
    "knight-resize/00000001_resized.jpg",
    "knight-resize/00000002_resized.jpg",
    "pawn_resized/00000001_resized.jpg",
    "pawn_resized/00000002_resized.jpg"
]


# Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· path -> index
image_path_map = {os.path.normpath(p): i for i, p in enumerate(image_paths_valid)}

# Î›Î¯ÏƒÏ„Î± Î¼Îµ index Ï„Ï‰Î½ query ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
query_indices = []
for q in query_filenames:
    q_norm = os.path.normpath(q)
    if q_norm in image_path_map:
        query_indices.append(image_path_map[q_norm])
    else:
        print(f"âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {q}")


features = tf_idf  # Î¼Ï€Î¿ÏÎµÎ¯Ï‚ ÎºÎ±Î¹ bovw_vectors Î±Î½ Î´ÎµÎ½ Î¸Î­Î»ÎµÎ¹Ï‚ TF-IDF
dist_matrix = cdist(features, features, metric='euclidean')

accuracies = []

for query_idx in query_indices:
    dists = dist_matrix[query_idx]
    dists[query_idx] = np.inf

    top_indices = np.argsort(dists)[:10]
    query_path = image_paths_valid[query_idx]
    query_label = os.path.normpath(query_path).split(os.sep)[0].lower()
    retrieved_paths = [image_paths_valid[i] for i in top_indices]
    retrieved_labels = [os.path.normpath(p).split(os.sep)[0].lower() for p in retrieved_paths]

    correct = sum(1 for lbl in retrieved_labels if lbl == query_label)
    accuracy = correct / 10.0
    accuracies.append(accuracy)

    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î¼Îµ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚
    fig, axs = plt.subplots(1, 11, figsize=(20, 4))
    fig.suptitle(f"Query: {query_label} | Accuracy: {accuracy:.2f}", fontsize=14)

    # Query image
    axs[0].imshow(mpimg.imread(query_path), cmap='gray')
    axs[0].set_title("Query")
    axs[0].axis("off")

    # Top-10
    for j, (img_path, lbl) in enumerate(zip(retrieved_paths, retrieved_labels), start=1):
        axs[j].imshow(mpimg.imread(img_path), cmap='gray')
        axs[j].set_title(lbl[:6])  # Ï€.Ï‡. "queen", "pawn", ...
        axs[j].axis("off")

    plt.tight_layout()
    plt.show()


# ÎœÎ­ÏƒÎ· Î±ÎºÏÎ¯Î²ÎµÎ¹Î±
mean_accuracy = np.mean(accuracies)
print(f"\nğŸ“Š ÎœÎ­ÏƒÎ· Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ (Top-10): {mean_accuracy:.2f}")

